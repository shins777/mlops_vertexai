{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Forusone(shins777@gmail.com)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Compare pipeline runs with Vertex AI Experiments\n",
    "* [Compare pipeline runs with Vertex AI Experiments](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/comparing_pipeline_runs.ipynb?hl=ko#scrollTo=JAPoU8Sm5E6e)\n",
    "\n",
    "### Dataset\n",
    "* [Iris dataset](https://www.tensorflow.org/datasets/catalog/iris)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8145,
     "status": "ok",
     "timestamp": 1735872754444,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "2b4ef9b72d43",
    "outputId": "34845192-d771-4312-c01a-0894da0127c2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --user google-cloud-aiplatform \\\n",
    "                                 google_cloud_pipeline_components \\\n",
    "                                 kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1621,
     "status": "ok",
     "timestamp": 1735872758789,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "_20JCVzIB6gr",
    "outputId": "0e10b946-4b7b-4fdd-ece6-3d6df0b6ae5f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1735872760703,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "s1gpnkkJ34Xf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Authentication to GCP\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1735872762640,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "t6_3Ipzy39Xe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Set GCP information\n",
    "PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5450,
     "status": "ok",
     "timestamp": 1735872770064,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "2vGmwps64AAn",
    "outputId": "104d8aaa-f514-48d0-a1ee-0ee3c36a1c74",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://mlops-0221/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'mlops-0221' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# @title Create a bucket.\n",
    "BUCKET_URI = f\"gs://mlops-0221\"\n",
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1735872772364,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "laQ0Rhqr4CId",
    "outputId": "48b8c99a-189e-49d6-ce27-4ad6d2f75f9e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE_ACCOUNT: 721521243942-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# @title Service account\n",
    "shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "print(f\"SERVICE_ACCOUNT: {SERVICE_ACCOUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3857,
     "status": "ok",
     "timestamp": 1735872777178,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "NbT59FB84ED2",
    "outputId": "84dbf911-f196-4713-8042-d4e0d08d909e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes made to gs://mlops-0221/\n",
      "No changes made to gs://mlops-0221/\n"
     ]
    }
   ],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4041,
     "status": "ok",
     "timestamp": 1735872781262,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "9fYX14c0LfmU",
    "outputId": "5f67ffa2-e083-47f8-d74a-1493763990e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/ai-platform/iris/classification/evaluate.csv [Content-Type=text/csv]...\n",
      "Copying gs://cloud-samples-data/ai-platform/iris/classification/train.csv [Content-Type=text/csv]...\n",
      "Copying gs://cloud-samples-data/ai-platform/iris/iris_data.csv [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/ai-platform/iris/iris_predict.csv [Content-Type=text/csv]...\n",
      "- [4 files][  5.4 KiB/  5.4 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://cloud-samples-data/ai-platform/iris/iris_target.csv [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-samples-data/ai-platform/iris/iris_test.csv [Content-Type=text/csv]...\n",
      "Copying gs://cloud-samples-data/ai-platform/iris/iris_training.csv [Content-Type=text/csv]...\n",
      "- [7 files][  8.4 KiB/  8.4 KiB]                                                \n",
      "Operation completed over 7 objects/8.4 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# @title Download training dataset\n",
    "DATASET_URI = \"gs://cloud-samples-data/ai-platform/iris\"\n",
    "PIPELINE_URI = f\"{BUCKET_URI}/pipeline/custom/experiments/iris\"\n",
    "\n",
    "!gsutil cp -r $DATASET_URI $PIPELINE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2419,
     "status": "ok",
     "timestamp": 1735872787496,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "pRUOFELefqf1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Import libraries and define constants\n",
    "\n",
    "import logging\n",
    "# General\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import kfp.compiler as compiler\n",
    "# Pipeline Experiments\n",
    "import kfp.dsl as dsl\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform_v1.types.pipeline_state import PipelineState\n",
    "from kfp.dsl import Metrics, Model, Output, component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1735872789749,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "OAY0QKZD8qNP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiments\n",
    "TASK = \"classification\"\n",
    "MODEL_TYPE = \"xgboost\"\n",
    "EXPERIMENT_NAME = f\"{PROJECT_ID}-{TASK}-{MODEL_TYPE}-{uuid.uuid1()}\"\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "TRAIN_URI = f\"{PIPELINE_URI}/iris_data.csv\"\n",
    "LABEL_URI = f\"{PIPELINE_URI}/iris_target.csv\"\n",
    "MODEL_URI = f\"{PIPELINE_URI}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1735872791535,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "Nz0nasrh8T3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Initialize Vertex AI SDK for Python\n",
    "vertex_ai.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1735872793021,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "XujRA5ueox9U",
    "outputId": "ecf64584-e46a-4423-ae13-3996b95cbcdb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-1:latest'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Set pre-built containers\n",
    "# For the latest list, see [Pre-built containers for training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers).\n",
    "# For the latest list, see [Pre-built containers for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers).\n",
    "\n",
    "TRAIN_IMAGE = vertex_ai.helpers.get_prebuilt_prediction_container_uri(\n",
    "    framework=\"xgboost\", framework_version=\"1.1\", accelerator=\"cpu\"\n",
    ")\n",
    "TRAIN_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1735872794949,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "jv_-vU46_eFN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Formalize the training as pipeline component\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9.0\",\n",
    "    packages_to_install=[\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"scikit-learn\",\n",
    "        \"xgboost\",\n",
    "    ],\n",
    ")\n",
    "def custom_trainer(\n",
    "    train_uri: str,\n",
    "    label_uri: str,\n",
    "    max_depth: int,\n",
    "    learning_rate: float,\n",
    "    boost_rounds: int,\n",
    "    model_uri: str,\n",
    "    metrics: Output[Metrics],\n",
    "    model_metadata: Output[Model],\n",
    "):\n",
    "\n",
    "    # import libraries\n",
    "    import logging\n",
    "    import uuid\n",
    "    from pathlib import Path as path\n",
    "\n",
    "    import pandas as pd\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # variables\n",
    "    gs_prefix = \"gs://\"\n",
    "    gcsfuse_prefix = \"/gcs/\"\n",
    "    train_path = train_uri.replace(gs_prefix, gcsfuse_prefix)\n",
    "    label_path = label_uri.replace(gs_prefix, gcsfuse_prefix)\n",
    "    model_path = model_uri.replace(gs_prefix, gcsfuse_prefix)\n",
    "\n",
    "    def get_logger():\n",
    "        \"\"\"\n",
    "        Get the logger\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(\n",
    "            logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "        )\n",
    "        logger.addHandler(handler)\n",
    "        return logger\n",
    "\n",
    "    def get_data(\n",
    "        train_path: str, label_path: str\n",
    "    ) -> (xgb.DMatrix, pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Get the data\n",
    "        Args:\n",
    "            train_path: the path of the train data\n",
    "            label_path: the path of the label data\n",
    "        Returns:\n",
    "            the train data and the label data\n",
    "        \"\"\"\n",
    "        # Load data into pandas, then use `.values` to get NumPy arrays\n",
    "        data = pd.read_csv(train_path).values\n",
    "        labels = pd.read_csv(label_path).values\n",
    "\n",
    "        # Convert one-column 2D array into 1D array for use with XGBoost\n",
    "        labels = labels.reshape((labels.size,))\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "            data, labels, test_size=0.2, random_state=7\n",
    "        )\n",
    "\n",
    "        # Load data into DMatrix object\n",
    "        dtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "        return dtrain, test_data, test_labels\n",
    "\n",
    "    def train_model(max_depth: int, eta: int, boost_rounds, dtrain: xgb.DMatrix):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        Args:\n",
    "            max_depth: the max depth of the model\n",
    "            eta: the eta of the model\n",
    "            boost_rounds: the boost rounds of the model\n",
    "            dtrain: the train data\n",
    "        Returns:\n",
    "            the trained model\n",
    "        \"\"\"\n",
    "        # Train XGBoost model\n",
    "        param = {\"max_depth\": max_depth, \"eta\": eta}\n",
    "        model = xgb.train(param, dtrain, num_boost_round=boost_rounds)\n",
    "        return model\n",
    "\n",
    "    def evaluate_model(model, test_data, test_labels):\n",
    "        \"\"\"\n",
    "        Evaluate the model\n",
    "        Args:\n",
    "            model: the trained model\n",
    "            test_data: the test data\n",
    "            test_labels: the test labels\n",
    "        Returns:\n",
    "            the accuracy of the model\n",
    "        \"\"\"\n",
    "        dtest = xgb.DMatrix(test_data)\n",
    "        pred = model.predict(dtest)\n",
    "        predictions = [round(value) for value in pred]\n",
    "        # Evaluate predictions\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        return accuracy\n",
    "\n",
    "    def save_model(model, model_path):\n",
    "        \"\"\"\n",
    "        Save the model\n",
    "        Args:\n",
    "            model: the trained model\n",
    "            model_path: the path of the model\n",
    "        \"\"\"\n",
    "        model_id = str(uuid.uuid1())\n",
    "        model_path = f\"{model_path}/{model_id}/model.bst\"\n",
    "        path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        model.save_model(model_path)\n",
    "\n",
    "    # Main ----------------------------------------------\n",
    "\n",
    "    dtrain, test_data, test_labels = get_data(train_path, label_path)\n",
    "    model = train_model(max_depth, learning_rate, boost_rounds, dtrain)\n",
    "    accuracy = evaluate_model(model, test_data, test_labels)\n",
    "    save_model(model, model_path)\n",
    "\n",
    "    # Metadata ------------------------------------------\n",
    "    metrics.log_metric(\"accurancy\", accuracy)\n",
    "    model_metadata.uri = model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1735872799453,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "9Gfr6pNLU-dB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Build a pipeline\n",
    "\n",
    "@dsl.pipeline(name=\"comparing_pipeline_experiments\")\n",
    "def pipeline(\n",
    "    train_uri: str,\n",
    "    label_uri: str,\n",
    "    max_depth: int,\n",
    "    learning_rate: float,\n",
    "    boost_rounds: int,\n",
    "    model_uri: str,\n",
    "):\n",
    "\n",
    "    custom_trainer(\n",
    "        train_uri=train_uri,\n",
    "        label_uri=label_uri,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        boost_rounds=boost_rounds,\n",
    "        model_uri=model_uri,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1735872801596,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "oYlLBGUSVibG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Compile the pipeline\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"comparing_pipeline_experiments.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95vG4-zPWc0B"
   },
   "source": [
    "## Submit and track pipeline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1735872803373,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "XPy0Jc8xXgpa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Submit pipeline runs\n",
    "\n",
    "runs = [\n",
    "    {\"max_depth\": 4, \"learning_rate\": 0.2, \"boost_rounds\": 10},\n",
    "    {\"max_depth\": 5, \"learning_rate\": 0.3, \"boost_rounds\": 20},\n",
    "    {\"max_depth\": 3, \"learning_rate\": 0.1, \"boost_rounds\": 30},\n",
    "    {\"max_depth\": 6, \"learning_rate\": 0.5, \"boost_rounds\": 40},\n",
    "    {\"max_depth\": 5, \"learning_rate\": 0.4, \"boost_rounds\": 30},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15251,
     "status": "ok",
     "timestamp": 1735872820169,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "G0hm1no_WY8o",
    "outputId": "f51b4777-2692-44a5-f4e8-7b0cf70c3ad1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, run in enumerate(runs):\n",
    "\n",
    "    job = vertex_ai.PipelineJob(\n",
    "        display_name=f\"{EXPERIMENT_NAME}-pipeline-run-{i}\",\n",
    "        template_path=\"comparing_pipeline_experiments.json\",\n",
    "        pipeline_root=PIPELINE_URI,\n",
    "        parameter_values={\n",
    "            \"train_uri\": TRAIN_URI,\n",
    "            \"label_uri\": LABEL_URI,\n",
    "            \"model_uri\": MODEL_URI,\n",
    "            **run,\n",
    "        },\n",
    "    )\n",
    "    job.submit(experiment=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1735872822639,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "dlCEJKfH5xR7",
    "outputId": "667a7a62-eb1a-4c91-dd20-e576b4dc2d7c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.learning_rate</th>\n",
       "      <th>param.max_depth</th>\n",
       "      <th>param.label_uri</th>\n",
       "      <th>param.boost_rounds</th>\n",
       "      <th>param.train_uri</th>\n",
       "      <th>param.model_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai-hangsik-classification-xgboost-ea8e3f4e-ef9...</td>\n",
       "      <td>comparing-pipeline-experiments-20250220145950</td>\n",
       "      <td>system.PipelineRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai-hangsik-classification-xgboost-ea8e3f4e-ef9...</td>\n",
       "      <td>comparing-pipeline-experiments-20250220145948</td>\n",
       "      <td>system.PipelineRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai-hangsik-classification-xgboost-ea8e3f4e-ef9...</td>\n",
       "      <td>comparing-pipeline-experiments-20250220145947</td>\n",
       "      <td>system.PipelineRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai-hangsik-classification-xgboost-ea8e3f4e-ef9...</td>\n",
       "      <td>comparing-pipeline-experiments-20250220145945</td>\n",
       "      <td>system.PipelineRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ai-hangsik-classification-xgboost-ea8e3f4e-ef9...</td>\n",
       "      <td>comparing-pipeline-experiments-20250220145943</td>\n",
       "      <td>system.PipelineRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "      <td>gs://mlops-0221/pipeline/custom/experiments/ir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name  \\\n",
       "0  ai-hangsik-classification-xgboost-ea8e3f4e-ef9...   \n",
       "1  ai-hangsik-classification-xgboost-ea8e3f4e-ef9...   \n",
       "2  ai-hangsik-classification-xgboost-ea8e3f4e-ef9...   \n",
       "3  ai-hangsik-classification-xgboost-ea8e3f4e-ef9...   \n",
       "4  ai-hangsik-classification-xgboost-ea8e3f4e-ef9...   \n",
       "\n",
       "                                        run_name            run_type    state  \\\n",
       "0  comparing-pipeline-experiments-20250220145950  system.PipelineRun  RUNNING   \n",
       "1  comparing-pipeline-experiments-20250220145948  system.PipelineRun  RUNNING   \n",
       "2  comparing-pipeline-experiments-20250220145947  system.PipelineRun  RUNNING   \n",
       "3  comparing-pipeline-experiments-20250220145945  system.PipelineRun  RUNNING   \n",
       "4  comparing-pipeline-experiments-20250220145943  system.PipelineRun  RUNNING   \n",
       "\n",
       "   param.learning_rate  param.max_depth  \\\n",
       "0                  0.4              5.0   \n",
       "1                  0.5              6.0   \n",
       "2                  0.1              3.0   \n",
       "3                  0.3              5.0   \n",
       "4                  0.2              4.0   \n",
       "\n",
       "                                     param.label_uri  param.boost_rounds  \\\n",
       "0  gs://mlops-0221/pipeline/custom/experiments/ir...                30.0   \n",
       "1  gs://mlops-0221/pipeline/custom/experiments/ir...                40.0   \n",
       "2  gs://mlops-0221/pipeline/custom/experiments/ir...                30.0   \n",
       "3  gs://mlops-0221/pipeline/custom/experiments/ir...                20.0   \n",
       "4  gs://mlops-0221/pipeline/custom/experiments/ir...                10.0   \n",
       "\n",
       "                                     param.train_uri  \\\n",
       "0  gs://mlops-0221/pipeline/custom/experiments/ir...   \n",
       "1  gs://mlops-0221/pipeline/custom/experiments/ir...   \n",
       "2  gs://mlops-0221/pipeline/custom/experiments/ir...   \n",
       "3  gs://mlops-0221/pipeline/custom/experiments/ir...   \n",
       "4  gs://mlops-0221/pipeline/custom/experiments/ir...   \n",
       "\n",
       "                                     param.model_uri  \n",
       "0  gs://mlops-0221/pipeline/custom/experiments/ir...  \n",
       "1  gs://mlops-0221/pipeline/custom/experiments/ir...  \n",
       "2  gs://mlops-0221/pipeline/custom/experiments/ir...  \n",
       "3  gs://mlops-0221/pipeline/custom/experiments/ir...  \n",
       "4  gs://mlops-0221/pipeline/custom/experiments/ir...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Check Pipeline run states\n",
    "vertex_ai.get_experiment_df(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188697,
     "status": "ok",
     "timestamp": 1735873011334,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "FA9W85vs7LLD",
    "outputId": "76342065-cffd-4ccc-922d-9e0825803bbf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline runs are still running...\n",
      "Pipeline runs are still running...\n",
      "Pipeline runs are still running...\n",
      "Pipeline experiment runs have completed\n"
     ]
    }
   ],
   "source": [
    "# @title Vertex AI Experiment is monitored based on pipeline run status.\n",
    "while True:\n",
    "    pipeline_experiments_df = vertex_ai.get_experiment_df(EXPERIMENT_NAME)\n",
    "    if any(\n",
    "        pipeline_state != \"COMPLETE\" for pipeline_state in pipeline_experiments_df.state\n",
    "    ):\n",
    "        print(\"Pipeline runs are still running...\")\n",
    "        if any(\n",
    "            pipeline_state == \"FAILED\"\n",
    "            for pipeline_state in pipeline_experiments_df.state\n",
    "        ):\n",
    "            print(\"At least one Pipeline run failed\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Pipeline experiment runs have completed\")\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2778,
     "status": "ok",
     "timestamp": 1733659978002,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "ISsK9Msi-Kqs",
    "outputId": "a5c7fb14-be3a-4706-f393-a5cde2d1b53f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline job name:  projects/721521243942/locations/us-central1/pipelineJobs/comparing-pipeline-experiments-20250220145950\n",
      "Pipeline Run UI link:  https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/comparing-pipeline-experiments-20250220145950?project=721521243942\n"
     ]
    }
   ],
   "source": [
    "# @title Get the PipelineJob resource using the experiment run name\n",
    "pipeline_experiments_df = vertex_ai.get_experiment_df(EXPERIMENT_NAME)\n",
    "job = vertex_ai.PipelineJob.get(pipeline_experiments_df.run_name[0])\n",
    "print(\"Pipeline job name: \", job.resource_name)\n",
    "print(\"Pipeline Run UI link: \", job._dashboard_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xbYQn5t5Noe"
   },
   "outputs": [],
   "source": [
    "# @title Delete the pipeline\n",
    "while True:\n",
    "    for i in range(0, len(runs)):\n",
    "        pipeline_job = vertex_ai.PipelineJob.get(pipeline_experiments_df.run_name[i])\n",
    "        if pipeline_job.state != PipelineState.PIPELINE_STATE_SUCCEEDED:\n",
    "            print(\"Pipeline job is still running...\")\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            print(\"Pipeline job is complete.\")\n",
    "            pipeline_job.delete()\n",
    "    break\n",
    "\n",
    "# Delete experiment\n",
    "exp = vertex_ai.Experiment(EXPERIMENT_NAME)\n",
    "exp.delete()\n",
    "\n",
    "# Delete the Cloud Storage bucket\n",
    "delete_bucket = False  # Set True for deletion\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -rf {BUCKET_URI}\n",
    "\n",
    "# Remove local files\n",
    "PIPELINE_TEMPLATE_FILE = \"comparing_pipeline_experiments.json\"\n",
    "\n",
    "!rm {PIPELINE_TEMPLATE_FILE}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
