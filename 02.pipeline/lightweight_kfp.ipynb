{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Forusone\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title:generic"
   },
   "source": [
    "# Lightweight KFP Pipelines\n",
    "* In this tutorial, you learn to use the KFP SDK to build lightweight Python function-based components, and then you learn to use Vertex AI Pipelines to execute the pipeline.\n",
    "* This lab simplifies the original notebook [Lightweight kfp](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/lightweight_functions_component_io_kfp.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## Install Vertex AI SDK for Python and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3625,
     "status": "ok",
     "timestamp": 1740028445485,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "NOFzTGzzL6no",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 kfp \\\n",
    "                                 \"numpy<2\" \\\n",
    "                                 google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12451,
     "status": "ok",
     "timestamp": 1740028527737,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "c97be6a73155",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Authentication to GCP\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740028535046,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "oM1iC_MfAts1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Set GCP information\n",
    "PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://mlops-0221\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3419,
     "status": "ok",
     "timestamp": 1740028544416,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "MzGDU7TWdts_",
    "outputId": "757351b1-3c46-4a38-8f7a-f6b09848c007",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://mlops-0221/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'mlops-0221' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "# @title Create a bucket.\n",
    "\n",
    "!gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1731,
     "status": "ok",
     "timestamp": 1735858013488,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "KovkBbqHL6nq",
    "outputId": "d38850db-837e-4291-a6a4-674ca9b61b80",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE_ACCOUNT: 721521243942-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# @title Service account\n",
    "shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "\n",
    "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "print(f\"SERVICE_ACCOUNT: {SERVICE_ACCOUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5436,
     "status": "ok",
     "timestamp": 1735858029813,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "r1kHmikQM2ie",
    "outputId": "e3a4fe25-8d31-4b91-b9ee-d40ca0ab43af",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes made to gs://mlops-0221/\n",
      "No changes made to gs://mlops-0221/\n"
     ]
    }
   ],
   "source": [
    "!gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "!gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "import_aip:mbsdk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Import libraries\n",
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from google.cloud import aiplatform\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import (Artifact, \n",
    "                     Dataset, \n",
    "                     Input, \n",
    "                     InputPath, \n",
    "                     Model, \n",
    "                     Output,\n",
    "                     OutputPath, \n",
    "                     component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FhqajZGfL6nq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Pipelines constants\n",
    "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline/shakespeare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3y_baPUbL6nq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Initialize Vertex AI SDK\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "IigaMQotL6nq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define Python function-based pipeline components\n",
    "@component(base_image=\"python:3.9\")\n",
    "def preprocess(\n",
    "    message: str,\n",
    "    out_dataset1: Output[Dataset],\n",
    "    out_dataset2: Output[Dataset],    \n",
    "    out_param_path: OutputPath(str),\n",
    "):\n",
    "    \"\"\"'\n",
    "    Mock' preprocessing step.\n",
    "    Writes out the passed in message to the output \"Dataset\"s and the output message.\n",
    "    \"\"\"\n",
    "    out_dataset1.metadata[\"hello\"] = \"there\"\n",
    "    out_dataset2.metadata[\"world\"] = \"OK\"\n",
    "\n",
    "    with open(out_dataset1.path, \"w\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "    with open(out_dataset2.path, \"w\") as f:\n",
    "        f.write(message)        \n",
    "        \n",
    "    with open(out_param_path, \"w\") as f:\n",
    "        f.write(message)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "adTHYS1IL6nq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define train component\n",
    "\n",
    "@component(base_image=\"python:3.9\")\n",
    "def train(\n",
    "    message: str,\n",
    "    \n",
    "    in_dataset1: Input[Dataset],\n",
    "    in_dataset2: Input[Dataset],\n",
    "\n",
    "    imported_dataset: Input[Dataset],\n",
    "\n",
    "    model: Output[Model],\n",
    "\n",
    "    num_steps: int = 3,\n",
    "\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"output_message\", str),  # Return parameter.\n",
    "        (\"generic_artifact\", Artifact),  # Return generic Artifact.\n",
    "    ],\n",
    "):\n",
    "    \"\"\"'Mock' Training step.\n",
    "    Combines the contents of dataset_one and dataset_two into the\n",
    "    output Model.\n",
    "    Constructs a new output_message consisting of message repeated num_steps times.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(in_dataset1.path) as input_file:\n",
    "        read_in_dataset1 = input_file.read()\n",
    "        print(f\"read_in_dataset1 : {read_in_dataset1}\")\n",
    "\n",
    "    with open(in_dataset2.path) as input_file:\n",
    "        read_in_dataset2 = input_file.read()\n",
    "        print(f\"read_in_dataset2 : {read_in_dataset2}\")\n",
    "\n",
    "    with open(model.path, \"w\") as f:\n",
    "        f.write(\"My Model\")\n",
    "        print(\"Model Saved:\", model)\n",
    "\n",
    "    model.metadata[\"accuracy\"] = 0.9\n",
    "    model.metadata[\"framework\"] = \"Tensorflow\"\n",
    "    model.metadata[\"time_to_train_in_seconds\"] = 257\n",
    "\n",
    "    output_message = \" \".join([message for _ in range(num_steps)])\n",
    "    artifact_contents = f\"{read_in_dataset1}\\n{read_in_dataset2}\"\n",
    "\n",
    "    return (output_message, artifact_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ytZaHwGZL6nr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define read_artifact_input component\n",
    "@component(base_image=\"python:3.9\")\n",
    "def read_artifact_input(\n",
    "    generic: Input[Artifact],\n",
    "):\n",
    "    with open(generic.path) as input_file:\n",
    "        generic_contents = input_file.read()\n",
    "        print(f\"generic contents: {generic_contents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "p7vNP-EzL6nr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Define a pipeline that uses your components and the Importer\n",
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"metadata-pipeline-v2\",\n",
    ")\n",
    "def pipeline(message: str):\n",
    "    # https://www.kubeflow.org/docs/components/pipelines/user-guides/components/importer-component/\n",
    "    importer = kfp.dsl.importer( \n",
    "        artifact_uri=\"gs://ml-pipeline-playground/shakespeare1.txt\",\n",
    "        artifact_class=Dataset,\n",
    "        reimport=False,\n",
    "    )\n",
    "    preprocess_task = preprocess(message=message)\n",
    "    \n",
    "    train_task = train(\n",
    "        message=preprocess_task.outputs[\"out_param_path\"],        \n",
    "        in_dataset1=preprocess_task.outputs[\"out_dataset1\"],\n",
    "        in_dataset2=preprocess_task.outputs[\"out_dataset2\"],\n",
    "        imported_dataset=importer.output,\n",
    "        \n",
    "        num_steps=5,\n",
    "    )\n",
    "    read_task = read_artifact_input(  # noqa: F841\n",
    "        generic=train_task.outputs[\"generic_artifact\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LC0JlqZnL6nr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Compile the pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"lightweight_kfp.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358965,
     "status": "ok",
     "timestamp": 1735858420310,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "bHNE84kDL6nu",
    "outputId": "fd2a0129-eeaa-4068-e955-ea92bd310045",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/metadata-pipeline-v2-20250220140150?project=721521243942\n",
      "PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250220140150\n"
     ]
    }
   ],
   "source": [
    "# @title Run the pipeline\n",
    "DISPLAY_NAME = \"shakespeare\"\n",
    "\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"lightweight_kfp.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"message\": \"Hello, World\"},\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1735860483766,
     "user": {
      "displayName": "Hangsik Shin",
      "userId": "04632555686962088332"
     },
     "user_tz": -540
    },
    "id": "425adbf24044",
    "outputId": "d3b38e75-f2d7-4cfb-deea-269620ce2f61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.base:Deleting PipelineJob : projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250102224741\n",
      "INFO:google.cloud.aiplatform.base:PipelineJob deleted. . Resource name: projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250102224741\n",
      "INFO:google.cloud.aiplatform.base:Deleting PipelineJob resource: projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250102224741\n",
      "INFO:google.cloud.aiplatform.base:Delete PipelineJob backing LRO: projects/721521243942/locations/us-central1/operations/1685094924975865856\n",
      "INFO:google.cloud.aiplatform.base:PipelineJob resource projects/721521243942/locations/us-central1/pipelineJobs/metadata-pipeline-v2-20250102224741 deleted.\n"
     ]
    }
   ],
   "source": [
    "# @title Delete the pipeline job\n",
    "job.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvedLNmgL6nu"
   },
   "outputs": [],
   "source": [
    "# @title Cleaning up\n",
    "delete_bucket = False\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI\n",
    "\n",
    "! rm lightweight_pipeline.yaml"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/lightweight_functions_component_io_kfp.ipynb",
     "timestamp": 1735857781144
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
