{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2024 Forusone\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"JAPoU8Sm5E6e"},"source":["# Model download from Hugging Face"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tFy3H3aPgx12","executionInfo":{"status":"ok","timestamp":1736067987427,"user_tz":-540,"elapsed":10013,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["# @title Install Vertex AI SDK and other required packages\n","%pip install --upgrade --user --quiet google-cloud-aiplatform \\\n","                                      huggingface_hub \\\n","                                      google-cloud-storage \\\n","                                      transformers"]},{"cell_type":"code","source":["# @title Define project information\n","PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n","LOCATION = \"us-central1\"  # @param {type:\"string\"}"],"metadata":{"cellView":"form","id":"MBY9UdUWH1d0","executionInfo":{"status":"ok","timestamp":1736067989807,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"984a0526fb68","executionInfo":{"status":"ok","timestamp":1736068006850,"user_tz":-540,"elapsed":14611,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["# @title GCP Authentication\n","\n","# Use OAuth to access the GCP environment.\n","import sys\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user(project_id=PROJECT_ID)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8d836e0210fe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736068019373,"user_tz":-540,"elapsed":10467,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"5fded6e4-948c-4980-a5f4-f3ae6310ae84"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Enter your token (input will not be visible): ··········\n","Add token as git credential? (Y/n) y\n"]}],"source":["# @title Authenticate your Hugging Face account\n","from huggingface_hub import interpreter_login\n","\n","interpreter_login()"]},{"cell_type":"code","source":["# @title Check Project ID and Location\n","\n","import os\n","\n","PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n","LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n","\n","PROJECT_ID, LOCATION"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOk0hGTrIXxA","executionInfo":{"status":"ok","timestamp":1736068021684,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"70d961de-4410-4273-fad4-fa5bad2bd680"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ai-hangsik', 'us-central1')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# @title Helper function to download a model and store it into GCS\n","from transformers import AutoModel, AutoTokenizer\n","from google.cloud import storage\n","\n","def model_download(model_name:str,\n","                   save_path:str,\n","                   bucket_name:str\n","                   ):\n","\n","    # Download model and tokenizer.\n","    model = AutoModel.from_pretrained(model_name)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    model.save_pretrained(save_path)\n","    tokenizer.save_pretrained(save_path)\n","\n","    # Save the model into Cloud storage.\n","    client = storage.Client()\n","    bucket = client.bucket(bucket_name)\n","\n","    for file_name in os.listdir(save_path):\n","      blob = bucket.blob(f\"{save_path}/{file_name}\")\n","      with open(os.path.join(save_path, file_name), \"rb\") as f:\n","        blob.upload_from_file(f)\n","\n","    return model, tokenizer"],"metadata":{"id":"yMlQhJEEXYAa","executionInfo":{"status":"ok","timestamp":1736068039833,"user_tz":-540,"elapsed":14189,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n","save_path = \"model\"\n","bucket_name = \"sllm_0106\"\n","\n","model, tokenizer = model_download(model_name,save_path,bucket_name)\n"],"metadata":{"id":"WISouu-jh3p3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1qwoO1IVNLMllwdCBViQKQomKaJtXWNEX","timestamp":1736041978985},{"file_id":"1YA_Q5gR_rsWKnQeO3b9LovVK3TsidHmG","timestamp":1736035804576},{"file_id":"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/open-models/serving/vertex_ai_text_generation_inference_gemma.ipynb","timestamp":1736019848158}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}