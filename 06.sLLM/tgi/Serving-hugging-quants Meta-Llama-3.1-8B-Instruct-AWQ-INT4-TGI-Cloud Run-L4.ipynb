{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2024 Forusone\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"JAPoU8Sm5E6e"},"source":["# Serving-hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4-TGI-Cloud Run-L4\n","* [Hugging Face TGI Metrics](https://huggingface.co/docs/text-generation-inference/en/reference/metrics)\n","* [Run LLM inference on Cloud Run GPUs with Hugging Face TGI (services)](https://cloud.google.com/run/docs/tutorials/gpu-llama3-with-tgi)\n","* [Deploy Meta Llama 3.1 8B with TGI DLC on Cloud Run](https://huggingface.co/docs/google-cloud/examples/cloud-run-tgi-deployment)"]},{"cell_type":"code","source":["# @title Define deployment constants\n","PROJECT_ID=\"ai-hangsik\" # @param {type:\"string\"}\n","LOCATION=\"us-central1\"  # @param {type:\"string\"}\n","CONTAINER_URI=\"us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu124.2-4.ubuntu2204.py311\" # @param {type:\"string\"}\n","SERVICE_NAME=\"hf-tgi-llama31-8b\" # @param {type:\"string\"}"],"metadata":{"id":"eaqts7U9Q1-h","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # @title Authentication\n","!gcloud auth login\n","!gcloud auth application-default login\n","!gcloud config set project {PROJECT_ID}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"os9UHzadQ17p","executionInfo":{"status":"ok","timestamp":1736819939064,"user_tz":-540,"elapsed":27520,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"141403db-79a1-466a-f46c-d7b0f29e8c64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Go to the following link in your browser, and complete the sign-in prompts:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=3sPFqNcfA0ClKxLUtqYCcs0Wp27OLD&prompt=consent&token_usage=remote&access_type=offline&code_challenge=55pvc5y2N-YIdQrCvzUBMxOa3wfcRsk1UEOPri9T7NQ&code_challenge_method=S256\n","\n","Once finished, enter the verification code provided in your browser: 4/0AanRRrthRE-3Gq9qRlbPQyMClYLQcPH-KqnwxlHtFrSQ8BBqk-CclvoI_OeeU4bWjzuqgw\n","\n","You are now logged in as [hangsik@google.com].\n","Your current project is [ai-hangsik].  You can change this setting by running:\n","  $ gcloud config set project PROJECT_ID\n","Go to the following link in your browser, and complete the sign-in prompts:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=VHgWhbbcO0ivT2Ae70HaXITrDYDks5&prompt=consent&token_usage=remote&access_type=offline&code_challenge=qdSqN6KyKvw780WDNa6nyG1DhEnGuG2FJZgHPGpcEU0&code_challenge_method=S256\n","\n","Once finished, enter the verification code provided in your browser: 4/0AanRRrunmFbFajolXVsyNL4cGipvOpNq1cnsA9v6DpyLD4KTtdZ7-sRKmx8yYj84sGDK3A\n","\n","Credentials saved to file: [/content/.config/application_default_credentials.json]\n","\n","These credentials will be used by any library that requests Application Default Credentials (ADC).\n","\n","Quota project \"ai-hangsik\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n","Updated property [core/project].\n"]}]},{"cell_type":"code","source":["# @title Enable Cloud Run APIs\n","!gcloud services enable run.googleapis.com"],"metadata":{"id":"qjJA64xDQ145"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Deploy a cloud run with a model\n","* Need to request Nvidia L4 GPU for Cloud Run. [Quota increase](https://cloud.google.com/run/quotas#increase).\n","* [TGI launcher arguments](https://huggingface.co/docs/text-generation-inference/en/basic_tutorials/launcher)\n"],"metadata":{"id":"TxxABdgfiUzU"}},{"cell_type":"code","source":["# @title Cloud run command to deploy a model.\n","!gcloud beta run deploy $SERVICE_NAME \\\n","    --image=$CONTAINER_URI \\\n","    --args=\"--model-id=hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4,--quantize=awq,--max-concurrent-requests=64\" \\\n","    --port=8080 \\\n","    --cpu=4 \\\n","    --memory=16Gi \\\n","    --no-cpu-throttling \\\n","    --gpu=1 \\\n","    --gpu-type=nvidia-l4 \\\n","    --max-instances=1 \\\n","    --concurrency=64 \\\n","    --region={LOCATION} \\\n","    --allow-unauthenticated"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JaP1z7aQ11x","executionInfo":{"status":"ok","timestamp":1736820420147,"user_tz":-540,"elapsed":346619,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"72757e13-60ee-4037-ddea-6e37f428c55e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deploying container to Cloud Run service [\u001b[1mhf-tgi-llama31-8b\u001b[m] in project [\u001b[1mai-hangsik\u001b[m] region [\u001b[1mus-central1\u001b[m]\n","Service [\u001b[1mhf-tgi-llama31-8b\u001b[m] revision [\u001b[1mhf-tgi-llama31-8b-00001-q2c\u001b[m] has been deployed and is serving \u001b[1m100\u001b[m percent of traffic.\n","Service URL: \u001b[1mhttps://hf-tgi-llama31-8b-721521243942.us-central1.run.app\u001b[m\n"]}]},{"cell_type":"markdown","source":["## Run a demo using Cloud Run proxy on local machine"],"metadata":{"id":"_1ZEcSEGjGur"}},{"cell_type":"markdown","source":["* Athenticate\n","```\n","gcloud auth login\n","```\n","\n","* Execute the follwing command on your local machine.\n","```\n","gcloud run services proxy $SERVICE_NAME --region $LOCATION\n"," --> gcloud run services proxy hf-tgi-llama31-8b --port 8088 --region us-central1\n","```\n","* You can see the following information.\n","```\n","/Users/hangsik$ gcloud run services proxy hf-tgi-llama31-8b --port 8088 --region us-central1\n","Proxying to Cloud Run service [hf-tgi-llama31-8b] in project [ai-hangsik] region [us-central1]\n","http://127.0.0.1:8088 proxies to https://hf-tgi-llama31-8b-o5gpdmpuwq-uc.a.run.app\n","```\n"],"metadata":{"id":"-hL91IGkjLr-"}},{"cell_type":"markdown","source":["* Execute the following command on your local machine.\n","```\n","curl http://localhost:8088/v1/chat/completions \\\n","    -X POST \\\n","    -H 'Content-Type: application/json' \\\n","    -d '{\n","        \"model\": \"tgi\",\n","        \"messages\": [\n","            {\n","                \"role\": \"system\",\n","                \"content\": \"You are a helpful assistant.\"\n","            },\n","            {\n","                \"role\": \"user\",\n","                \"content\": \"What is Deep Learning?\"\n","            }\n","        ],\n","        \"max_tokens\": 128\n","    }'\n","```\n","\n","* Response\n","```\n","{\"object\":\"chat.completion\",\"id\":\"\",\"created\":1736821056,\"model\":\"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\",\"system_fingerprint\":\"2.4.0-native\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Deep Learning is a subfield of machine learning (a subset of artificial intelligence) that uses multi-layered artificial neural networks to analyze and learn from data. These neural networks are inspired by the structure and function of the human brain, where connections between layers of neurons enable complex patterns to be recognized and learned.\\n\\nOver the last decade, Deep Learning has gained tremendous popularity due to its remarkable performance in various applications such as:\\n\\n1. **Image Classification**: Self-driving cars, facial recognition, object detection in video footage.\\n2. **Natural Language Processing (NLP)**: Sentiment analysis, language translation, text summarization, chatbots.\\n3\"},\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":46,\"completion_tokens\":128,\"total_tokens\":174}}/Users/hangsik$\n","```"],"metadata":{"id":"1qHdDmUpk9BL"}}],"metadata":{"colab":{"provenance":[{"file_id":"1ufUtoMIGt4zlATBWTzAjBl5NImEUBxKI","timestamp":1736613834029},{"file_id":"1aXaBE0WEzfwmbFW-4vi272hlh9DKW2w7","timestamp":1736415646512},{"file_id":"1SlaHkIfriiF9fy0rmKDDiXpK_Z60iTrs","timestamp":1735130190117},{"file_id":"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb","timestamp":1722952953319}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}