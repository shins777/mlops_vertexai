{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2024 Forusone\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"JAPoU8Sm5E6e"},"source":["# Deploy Llama 3.1 8B vLLM in GCS on Vertex AI\n","* [model_garden_pytorch_llama3_1_deployment.ipynb](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_llama3_1_deployment.ipynb)"]},{"cell_type":"code","source":["# @title Install and upgrade Vertex AI SDK.\n","! pip3 install --upgrade --quiet google-cloud-aiplatform"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPfEDElgrKAE","executionInfo":{"status":"ok","timestamp":1737014134606,"user_tz":-540,"elapsed":29869,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"a8fcaa1c-c3ea-4461-f6ca-348c2b38a655"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["PROJECT_ID=\"ai-hangsik\" # @param {type:\"string\"}\n","LOCATION=\"us-central1\"  # @param {type:\"string\"}"],"metadata":{"id":"1OIBO_Iu5NYa","executionInfo":{"status":"ok","timestamp":1737014134607,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# @title Authentication\n","!gcloud auth login\n","!gcloud auth application-default login\n","!gcloud config set project {PROJECT_ID}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BQSt5tMNBmZ","executionInfo":{"status":"ok","timestamp":1737015734936,"user_tz":-540,"elapsed":27720,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"b702cb3d-4dad-4a40-ad6d-4e939b02dc0c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Go to the following link in your browser, and complete the sign-in prompts:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=pVSvxOFLWskHU2EisB3h5jwdGHPQi3&prompt=consent&token_usage=remote&access_type=offline&code_challenge=0wV1OD2HSTOBwIA3P9R3cKItkhxYLq1mdXZLK8ppnWM&code_challenge_method=S256\n","\n","Once finished, enter the verification code provided in your browser: 4/0AanRRrulJI1-tAgSbW-C_eDZ21Hie-gZhL9VPL7aKLgdx5y6SstLtlttgZ8h-hm1_k_QMA\n","\n","You are now logged in as [hangsik@google.com].\n","Your current project is [None].  You can change this setting by running:\n","  $ gcloud config set project PROJECT_ID\n","Go to the following link in your browser, and complete the sign-in prompts:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=Cr1w7QzKBBdtkdmY5VSzkXjJEmxq8g&prompt=consent&token_usage=remote&access_type=offline&code_challenge=JRu5s3katmOrlcB3jc820YaI_GhaJlZH797ciir2KEs&code_challenge_method=S256\n","\n","Once finished, enter the verification code provided in your browser: 4/0AanRRrsUM-9Mi3ZpIrSz0Q8f-FV491WqjZxbKm2XuIzAhuBq3X0DkkUCAlmKLJPtkv-KNg\n","\n","Credentials saved to file: [/content/.config/application_default_credentials.json]\n","\n","These credentials will be used by any library that requests Application Default Credentials (ADC).\n","\u001b[1;33mWARNING:\u001b[0m \n","Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n","\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n","\n","To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n","Updated property [core/project].\n"]}]},{"cell_type":"code","source":["# @title Initialize Vertex AI\n","from typing import Tuple\n","from google.cloud import aiplatform\n","\n","aiplatform.init(project=PROJECT_ID, location=LOCATION)"],"metadata":{"id":"Y_jSwbeaNC3p","executionInfo":{"status":"ok","timestamp":1737015819831,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# @title Gets the default SERVICE_ACCOUNT.\n","shell_output = ! gcloud projects describe $PROJECT_ID\n","project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n","SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n","print(\"Using this default Service Account:\", SERVICE_ACCOUNT)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBpLp7lSMyMe","executionInfo":{"status":"ok","timestamp":1737015743442,"user_tz":-540,"elapsed":1130,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"b14a5b96-33ee-44b3-e4a9-f4acf76f574c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Using this default Service Account: 721521243942-compute@developer.gserviceaccount.com\n"]}]},{"cell_type":"code","source":["# The pre-built serving docker images.\n","import os\n","\n","MODEL_ID = \"Phi-3.5-MoE-instruct\"\n","model_path_prefix = \"microsoft\"\n","model_id = os.path.join(model_path_prefix, MODEL_ID)\n","\n","VLLM_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240926_1639_RC00\"\n","\n","vllm_dtype = \"bfloat16\"\n","max_model_len = 131072\n","accelerator_type = \"NVIDIA_L4\"\n","accelerator_count = 8\n","machine_type = \"g2-standard-96\"\n","enable_trust_remote_code = True\n","gpu_memory_utilization = 0.95\n","\n","def deploy_model_vllm(\n","    model_name: str,\n","    model_id: str,\n","    service_account: str,\n","    base_model_id: str = None,\n","    machine_type: str = \"g2-standard-8\",\n","    accelerator_type: str = \"NVIDIA_L4\",\n","    accelerator_count: int = 1,\n","    gpu_memory_utilization: float = 0.9,\n","    max_model_len: int = 4096,\n","    dtype: str = \"auto\",\n","    enable_trust_remote_code: bool = False,\n","    enforce_eager: bool = False,\n","    enable_lora: bool = False,\n","    enable_chunked_prefill: bool = False,\n","    enable_prefix_cache: bool = False,\n","    host_prefix_kv_cache_utilization_target: float = 0.0,\n","    max_loras: int = 1,\n","    max_cpu_loras: int = 8,\n","    use_dedicated_endpoint: bool = False,\n","    max_num_seqs: int = 256,\n","    model_type: str = None,\n",") -> Tuple[aiplatform.Model, aiplatform.Endpoint]:\n","    \"\"\"Deploys trained models with vLLM into Vertex AI.\"\"\"\n","    endpoint = aiplatform.Endpoint.create(\n","        display_name=f\"{model_name}-endpoint\",\n","        dedicated_endpoint_enabled=use_dedicated_endpoint,\n","    )\n","\n","    if not base_model_id:\n","        base_model_id = model_id\n","\n","    # See https://docs.vllm.ai/en/latest/models/engine_args.html for a list of possible arguments with descriptions.\n","    vllm_args = [\n","        \"python\",\n","        \"-m\",\n","        \"vllm.entrypoints.api_server\",\n","        \"--host=0.0.0.0\",\n","        \"--port=8080\",\n","        f\"--model={model_id}\",\n","        f\"--tensor-parallel-size={accelerator_count}\",\n","        \"--swap-space=16\",\n","        f\"--gpu-memory-utilization={gpu_memory_utilization}\",\n","        f\"--max-model-len={max_model_len}\",\n","        f\"--dtype={dtype}\",\n","        f\"--max-loras={max_loras}\",\n","        f\"--max-cpu-loras={max_cpu_loras}\",\n","        f\"--max-num-seqs={max_num_seqs}\",\n","        \"--disable-log-stats\",\n","    ]\n","\n","    if enable_trust_remote_code:\n","        vllm_args.append(\"--trust-remote-code\")\n","\n","    if enforce_eager:\n","        vllm_args.append(\"--enforce-eager\")\n","\n","    if enable_lora:\n","        vllm_args.append(\"--enable-lora\")\n","\n","    if enable_chunked_prefill:\n","        vllm_args.append(\"--enable-chunked-prefill\")\n","\n","    if enable_prefix_cache:\n","        vllm_args.append(\"--enable-prefix-caching\")\n","\n","    if 0 < host_prefix_kv_cache_utilization_target < 1:\n","        vllm_args.append(\n","            f\"--host-prefix-kv-cache-utilization-target={host_prefix_kv_cache_utilization_target}\"\n","        )\n","\n","    if model_type:\n","        vllm_args.append(f\"--model-type={model_type}\")\n","\n","    env_vars = {\n","        \"MODEL_ID\": base_model_id,\n","        \"DEPLOY_SOURCE\": \"notebook\",\n","    }\n","\n","    # HF_TOKEN is not a compulsory field and may not be defined.\n","    try:\n","        if HF_TOKEN:\n","            env_vars[\"HF_TOKEN\"] = HF_TOKEN\n","    except NameError:\n","        pass\n","\n","    model = aiplatform.Model.upload(\n","        display_name=model_name,\n","        serving_container_image_uri=VLLM_DOCKER_URI,\n","        serving_container_args=vllm_args,\n","        serving_container_ports=[8080],\n","        serving_container_predict_route=\"/generate\",\n","        serving_container_health_route=\"/ping\",\n","        serving_container_environment_variables=env_vars,\n","        serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n","        serving_container_deployment_timeout=7200,\n","    )\n","    print(\n","        f\"Deploying {model_name} on {machine_type} with {accelerator_count} {accelerator_type} GPU(s).\"\n","    )\n","\n","    model.deploy(\n","        endpoint=endpoint,\n","        machine_type=machine_type,\n","        accelerator_type=accelerator_type,\n","        accelerator_count=accelerator_count,\n","        deploy_request_timeout=1800,\n","        service_account=service_account,\n","        system_labels={\n","            \"NOTEBOOK_NAME\": \"model_garden_phi3_deployment.ipynb\",\n","        },\n","    )\n","    print(\"endpoint_name:\", endpoint.name)\n","\n","    return model, endpoint\n","\n","\n","use_dedicated_endpoint = True\n","\n","\n","deploy_model_vllm(\n","    model_name=\"Phi-3.5-MoE-instruct\",\n","    model_id=model_id,\n","    service_account=SERVICE_ACCOUNT,\n","    machine_type=machine_type,\n","    accelerator_type=accelerator_type,\n","    accelerator_count=accelerator_count,\n","    max_model_len=max_model_len,\n","    gpu_memory_utilization=gpu_memory_utilization,\n","    dtype=vllm_dtype,\n","    enable_trust_remote_code=enable_trust_remote_code,\n","    use_dedicated_endpoint=use_dedicated_endpoint,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"id":"XoXwAiXN5ACh","executionInfo":{"status":"error","timestamp":1737017948233,"user_tz":-540,"elapsed":1365882,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"a982b13f-f083-43ed-9bf9-b88917b2192f"},"execution_count":15,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n","  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n","INFO:google.cloud.aiplatform.models:Creating Endpoint\n","INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/721521243942/locations/us-central1/endpoints/1412046708459700224/operations/6808407893063237632\n","INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/721521243942/locations/us-central1/endpoints/1412046708459700224\n","INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n","INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/721521243942/locations/us-central1/endpoints/1412046708459700224')\n","INFO:google.cloud.aiplatform.models:Creating Model\n","INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/721521243942/locations/us-central1/models/5745314392501649408/operations/7877449854610309120\n","INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/721521243942/locations/us-central1/models/5745314392501649408@1\n","INFO:google.cloud.aiplatform.models:To use this Model in another session:\n","INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/721521243942/locations/us-central1/models/5745314392501649408@1')\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Deploying Phi-3.5-MoE-instruct on g2-standard-96 with 8 NVIDIA_L4 GPU(s).\n"]},{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/721521243942/locations/us-central1/endpoints/1412046708459700224\n","INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/721521243942/locations/us-central1/endpoints/1412046708459700224/operations/2277786667928518656\n","INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/721521243942/locations/us-central1/endpoints/1412046708459700224\n"]},{"output_type":"stream","name":"stdout","text":["endpoint_name: 1412046708459700224\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'models' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-fd8b6e64baf5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m models[\"vllm_gpu\"], endpoints[\"vllm_gpu\"] = deploy_model_vllm(\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Phi-3.5-MoE-instruct\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4kMyM_HP4__w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ylXLicdt4_9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5Eu6dMvG4_6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C5pF1zi94_4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UvgeqlgN4_1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Define deployment constants\n","import datetime\n","now = datetime.datetime.now()\n","\n","PROJECT_ID=\"ai-hangsik\" # @param {type:\"string\"}\n","LOCATION=\"us-central1\"  # @param {type:\"string\"}\n","\n","MODEL_BUCKET_URI =\"gs://sllm_0106/llama3.1_8b_inst\" # @param {type:\"string\"}\n","VLLM_DOCKER_URI = \"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/vllm-inference.cu121.0-5.ubuntu2204.py310\" # @param {type:\"string\"}\n","\n","MODEL_ID = \"Meta-Llama-3.1-8B-Instruct\" # @param {type:\"string\"}\n","MODEL_DISPLAY_NAME = f\"{MODEL_ID}-{now}\"\n","ENDPOINT_DISPLAY_NAME = f\"{MODEL_ID}-endpoint\" # @param {type:\"string\"}\n"],"metadata":{"id":"eaqts7U9Q1-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Authentication\n","!gcloud auth login\n","!gcloud auth application-default login\n","!gcloud config set project {PROJECT_ID}"],"metadata":{"id":"os9UHzadQ17p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Initialize Vertex AI\n","from google.cloud import aiplatform\n","\n","aiplatform.init(project=PROJECT_ID, location=LOCATION)"],"metadata":{"id":"rs-rG7CnDjLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Gets the default SERVICE_ACCOUNT.\n","shell_output = ! gcloud projects describe $PROJECT_ID\n","project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n","SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n","print(\"Using this default Service Account:\", SERVICE_ACCOUNT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWdiRwKHDvcD","executionInfo":{"status":"ok","timestamp":1736841320029,"user_tz":-540,"elapsed":925,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"a6785ad6-d016-4d49-ebfa-daff14f8e707"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using this default Service Account: 721521243942-compute@developer.gserviceaccount.com\n"]}]},{"cell_type":"code","source":["# @title Set accelerator.\n","# Find Vertex AI prediction supported accelerators and regions [here](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute).\n","MACHINE_TYPE = \"g2-standard-12\" # @param {type:\"string\"}\n","ACCELERATOR_TYPE = \"NVIDIA_L4\" # @param {type:\"string\"}\n","ACCELERATOR_COUNT = 1 # @param {type:\"string\"}\n"],"metadata":{"id":"Bd43MP3oHh66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Tuple\n","from google.cloud import aiplatform\n","\n","# See https://docs.vllm.ai/en/latest/serving/engine_args.html for a list of possible arguments with descriptions.\n","vllm_args = [\n","    \"python\",\n","    \"-m\",\n","    \"vllm.entrypoints.api_server\",\n","    \"--host=0.0.0.0\",\n","    \"--port=8080\",\n","    f\"--model={MODEL_ID}\",\n","    f\"--tensor-parallel-size={ACCELERATOR_COUNT}\",\n","    \"--swap-space=16\",\n","    f\"--gpu-memory-utilization=0.95\",\n","    f\"--max-model-len=8192\",\n","    f\"--dtype=auto\",\n","    f\"--max-loras=1\",\n","    f\"--max-cpu-loras=8\",\n","    f\"--max-num-seqs=256\",\n","    \"--disable-log-stats\",\n","#     \"--trust-remote-code\",\n","#     \"--enforce-eager\",\n","#     \"--enable-lora\",\n","#     \"--model-type=llama\",\n"," ]\n","\n","env_vars = {\n","    \"MODEL_ID\": MODEL_ID,\n","    \"DEPLOY_SOURCE\": \"notebook\",\n","}"],"metadata":{"id":"fD6oDx5wHtpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = aiplatform.Model.upload(\n","    display_name=MODEL_DISPLAY_NAME,\n","    artifact_uri=MODEL_BUCKET_URI,\n","    serving_container_image_uri=VLLM_DOCKER_URI,\n","    serving_container_args=vllm_args,\n","    serving_container_ports=[8080],\n","    serving_container_predict_route=\"/generate\",\n","    serving_container_health_route=\"/ping\",\n","    serving_container_environment_variables=env_vars,\n","    serving_container_shared_memory_size_mb=(16 * 1024),  # 16 GB\n","    serving_container_deployment_timeout=7200,\n",")\n","print(\n","    f\"Deploying {MODEL_DISPLAY_NAME} on {MACHINE_TYPE} with {ACCELERATOR_COUNT} {ACCELERATOR_TYPE} GPU(s).\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkO-fheRJNId","executionInfo":{"status":"ok","timestamp":1736841468840,"user_tz":-540,"elapsed":135842,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"bd3a98fa-3b71-4340-a00a-9726fc3d5edb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n","  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n","INFO:google.cloud.aiplatform.models:Creating Model\n","INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/721521243942/locations/us-central1/models/6974234140820373504/operations/125048453859377152\n","INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/721521243942/locations/us-central1/models/6974234140820373504@1\n","INFO:google.cloud.aiplatform.models:To use this Model in another session:\n","INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/721521243942/locations/us-central1/models/6974234140820373504@1')\n"]},{"output_type":"stream","name":"stdout","text":["Deploying Meta-Llama-3.1-8B-Instruct-2025-01-14 07:54:18.528202 on g2-standard-12 with 1 NVIDIA_L4 GPU(s).\n"]}]},{"cell_type":"code","source":["endpoint = aiplatform.Endpoint.create(\n","        display_name = ENDPOINT_DISPLAY_NAME,\n","        dedicated_endpoint_enabled=False,\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bVuIGo5OysPX","executionInfo":{"status":"ok","timestamp":1736841470253,"user_tz":-540,"elapsed":1402,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"748422cf-100c-4940-fa2c-172527bc3217"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.models:Creating Endpoint\n","INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/721521243942/locations/us-central1/endpoints/7602948083722223616/operations/8303585377164197888\n","INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/721521243942/locations/us-central1/endpoints/7602948083722223616\n","INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n","INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/721521243942/locations/us-central1/endpoints/7602948083722223616')\n"]}]},{"cell_type":"code","source":["model.deploy(\n","    endpoint=endpoint,\n","    machine_type=MACHINE_TYPE,\n","    accelerator_type=ACCELERATOR_TYPE,\n","    accelerator_count=ACCELERATOR_COUNT,\n","    deploy_request_timeout=1800,\n","    service_account=SERVICE_ACCOUNT,\n",")\n","print(\"endpoint_name:\", endpoint.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6N3OFBzJuvj","executionInfo":{"status":"ok","timestamp":1736842964993,"user_tz":-540,"elapsed":1494725,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"3d80bf66-589c-41cf-bfcd-104e792fd3b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/721521243942/locations/us-central1/endpoints/7602948083722223616\n","INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/721521243942/locations/us-central1/endpoints/7602948083722223616/operations/7972007854599045120\n","INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/721521243942/locations/us-central1/endpoints/7602948083722223616\n"]},{"output_type":"stream","name":"stdout","text":["endpoint_name: 7602948083722223616\n"]}]},{"cell_type":"code","source":["import os\n","\n","ENDPOINT_DISPLAY_NAME = \"Phi-3.5-MoE-instruct-endpoint\"\n","def predict_vllm(prompt: str,):\n","\n","    ENDPOINT_ID = next(\n","                          (endpoint.name for endpoint in aiplatform.Endpoint.list()\n","                          if endpoint.display_name == ENDPOINT_DISPLAY_NAME),\n","                          None\n","                      )\n","    endpoint = aiplatform.Endpoint(f\"projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/{ENDPOINT_ID}\")\n","\n","    instance = {\n","        \"prompt\": prompt,\n","        \"max_tokens\": 128,\n","        \"temperature\": 1.0,\n","        \"top_p\": 1.0,\n","        \"top_k\": 10,\n","        \"raw_response\": False,\n","    }\n","\n","    instances = [instance]\n","\n","    response = endpoint.predict(\n","        instances=instances,\n","        use_dedicated_endpoint=True\n","    )\n","\n","    return response"],"metadata":{"id":"p4qvmaK2TqYP","executionInfo":{"status":"ok","timestamp":1737018404895,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["prompt = \"What is a car?\"\n","\n","response = predict_vllm(prompt=prompt)\n","\n","for prediction in response.predictions:\n","    print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtWmFTg7TicI","executionInfo":{"status":"ok","timestamp":1737018409549,"user_tz":-540,"elapsed":2846,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"d69476ed-4259-45b6-f4c7-6245403fb136"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt:\n","What is a car?\n","Output:\n"," A car, also known as an automobile or motorcar, is a wheeled motor vehicle used for transportation. Most definitions of cars say they run primarily on roads, seat one to eight people, have four wheels, and mainly transport people rather than goods. Cars were developed in the late 19th century as a successor to horse-drawn carriages and have since become a major part of modern life.\n","\n","Cars are powered by internal combustion engines, which burn fuel, or electric motors, which use electricity stored in batteries or other storage devices. They come in various\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1cJkL_AeEruKDWFoTdQx5y32wZKv9LEZT","timestamp":1736823364211},{"file_id":"1uOCPG6QrRLsU5wi8-_RxJ5OIjs1TRtwm","timestamp":1736821793423},{"file_id":"1ufUtoMIGt4zlATBWTzAjBl5NImEUBxKI","timestamp":1736613834029},{"file_id":"1aXaBE0WEzfwmbFW-4vi272hlh9DKW2w7","timestamp":1736415646512},{"file_id":"1SlaHkIfriiF9fy0rmKDDiXpK_Z60iTrs","timestamp":1735130190117},{"file_id":"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb","timestamp":1722952953319}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}